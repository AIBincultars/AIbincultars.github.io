<?xml version="1.0" encoding="utf-8"?>
<search> 
  
  
    
    <entry>
      <title>pytorch搭建神经网络</title>
      <link href="/2024/04/29/pytorch-da-jian-shen-jing-wang-luo/"/>
      <url>/2024/04/29/pytorch-da-jian-shen-jing-wang-luo/</url>
      
        <content type="html"><![CDATA[]]></content>
      
      
      <categories>
          
          <category> 神经网络搭建 </category>
          
      </categories>
      
      
    </entry>
    
    
    
    <entry>
      <title>评估指标(tensorflow和keras)</title>
      <link href="/2024/04/25/ping-gu-zhi-biao-tensorflow/"/>
      <url>/2024/04/25/ping-gu-zhi-biao-tensorflow/</url>
      
        <content type="html"><![CDATA[<p>Keras和tensorflow的评估指标很相似,评估功能都内置在函数库中。</p><p>评估功能呢包括计算accuracy,loss和其他自定义指标。</p><p>一.tensorflow的评估步骤</p><p>1.编译模型</p><p>在 训练 和 评估 开始之前,需要先 编译模型 以及 指定损失函数和优化器。</p><p>可以调用 compile 方法来完成。</p><pre><code class="python">model.compile(optimizer=&#39;adam&#39;,loss=&#39;binary_crossentropy&#39;,metrics=[&#39;accuracy&#39;])#optimizer为优化器,loss为损失函数,metrcis为评估方式</code></pre><p>2.评估模型</p><p>调用模型的evaluate方法,需要提供评估数据集作为输入，并且指定评估的batch_size。</p><pre><code class="python">loss,accuracy=model.evaluate(test_dataset,batch_size=32)</code></pre><p>evaluate方法会返回一个包含loss和accuracy的list,可以根据需要选择这些值。</p><p>3.自定义方法</p><p>我们可以自定义评估函数,实例代码如下</p><pre><code class="python">import tensorflow as tfdef custom_metric(y_true,y_pred):    #自定义内容    return ...model.compile(optimizer=&#39;adam&#39;,loss=&#39;binary_crossentropy&#39;,metrics=[custom_metric])</code></pre><p>二.keras的评估指标</p><p>1.与tensorflow相同，第一步为编译模型</p><p>若以accuracy为评估指标，要在metrics中填入accuracy</p><pre><code class="python">model.compile(optimizer=&#39;adam&#39;, loss=&#39;categorical_crossentropy&#39;, metrics=[&#39;accuracy&#39;])</code></pre><p>若以loss为评估指标,要在metrics中填入loss</p><pre><code class="python">model.compile(optimizer=&#39;adam&#39;, loss=&#39;categorical_crossentropy&#39;, metrics=[&#39;loss&#39;])</code></pre><p>2.自定义评估</p><pre><code class="python">import keras.backend as Kdef custom_metric(y_true, y_pred):    # 自定义评估指标的计算逻辑    # 根据真实标签和预测标签计算指标值    return ...model.compile(optimizer=&#39;adam&#39;, loss=&#39;categorical_crossentropy&#39;, metrics=[custom_metric])</code></pre>]]></content>
      
      
      <categories>
          
          <category> 评估模型的方法 </category>
          
      </categories>
      
      
    </entry>
    
    
    
    <entry>
      <title>评估指标(sklearn)</title>
      <link href="/2024/04/25/ping-gu-zhi-biao/"/>
      <url>/2024/04/25/ping-gu-zhi-biao/</url>
      
        <content type="html"><![CDATA[<p>“评估指标” 用来评价机器学习模型的性能 </p><p>常见的有准确率(accuracy),精确率(precision),召回率(recall),f1分数(F1 Score)</p><p>指标的英文-“metrics”</p><p>sklearn库中的评估指标 </p><p>1)accuracy-准确率</p><p>a. 模型预测正确的样本 占 总样本数 的比例,用于评估 分类模型 的性能</p><p>b.使用函数 </p><pre><code class="python">sklearn.metrics.accuracy_score</code></pre><p>c.示例代码</p><pre><code class="python">from sklearn.metrics import accuracy_score# 真实标签y_true = [0, 1, 1, 0, 1]# 预测标签y_pred = [0, 1, 0, 0, 1]# 计算准确率accuracy = accuracy_score(y_true, y_pred)print(&quot;Accuracy:&quot;, accuracy)</code></pre><p>2)precision-精确率,recall-召回率</p><p>a.precision和recall用来评估 二分类模型</p><p>precision 衡量模型预测中为 正类的样本中实际为正类的比例</p><p>recall 衡量 实际为正类的样本 被 正确预测 的正类比例</p><p>b.使用函数</p><pre><code class="python">sklearn.metrics.precision_scoresklearn.metrics.recall_scorec.示例代码```pythonfrom sklearn.metrics import precision_score, recall_score# 真实标签y_true = [0, 1, 1, 0, 1]# 预测标签y_pred = [0, 1, 0, 0, 1]# 计算精确率precision = precision_score(y_true, y_pred)print(&quot;Precision:&quot;, precision)# 计算召回率recall = recall_score(y_true, y_pred)print(&quot;Recall:&quot;, recall)</code></pre><p>3)f1_score - F1分数</p><p>a.f1分数 综合考虑了precision和recall的评估指标,用于平衡二者之间的权衡关系</p><p>b.使用函数</p><pre><code class="python">sklearn.metrics.f1_score</code></pre><p>c.示例代码</p><pre><code class="python">from sklearn.metrics import f1_score# 真实标签y_true = [0, 1, 1, 0, 1]# 预测标签y_pred = [0, 1, 0, 0, 1]# 计算F1分数f1 = f1_score(y_true, y_pred)print(&quot;F1 Score:&quot;, f1)</code></pre>]]></content>
      
      
      <categories>
          
          <category> 评估模型的方法 </category>
          
      </categories>
      
      
    </entry>
    
    
    
    <entry>
      <title>日志记录</title>
      <link href="/2024/04/25/ri-zhi-ji-lu/"/>
      <url>/2024/04/25/ri-zhi-ji-lu/</url>
      
        <content type="html"><![CDATA[<p>为了使模型训练可视化，python内置了logging库,比用print打印更省内存</p><p>一.先导入logging库</p><pre><code class="python">import logging</code></pre><p>二.日志级别以及对应函数</p><p>1)日志优先级</p><p> CRIRICAL &gt; ERROR &gt; WARNING &gt; INFO &gt; DEBUG</p><p> 当将日志级别设为某个级别时，则低于该级别的日志将不会输出</p><p> 若日志级别为INFO，则DEBUG将不会输出</p><p>DEBUG : 开发阶段使用，用来定位问题或显示程序运行细节</p><p>INFO : 用来输出一般信息，确认其正常工作</p><p>WARNING ： 用来输出警告信息,但不影响程序正常运行</p><p>ERROR : 报错信息，程序的一些功能以及不可用</p><p>CRITICAL ： 严重错误信息，程序已经不可以执行</p><p>2)基本使用</p><pre><code class="python">import logging#logging.basicConfig 相当于一个组合器，可以不在单独设置。logging.basicConfig(level = logging.INFO,format = &#39;%(asctime)s - %(name)s - %(levelname)s - %(message)s&#39;) #level中设置当前程序中日志的等级，低于该等级的不会输出,format中是输出的格式。#创建了一个日志记录器实例名字自拟。logger = logging.getLogger(_name_)#一下就是输出信息内容logger.info(&quot;Start print log&quot;)logger.debug(&quot;Do something&quot;)logger.warning(&quot;Something maybe fail.&quot;)logger.info(&quot;Finish&quot;)#输出后debug不会输出因为等级比info低</code></pre><p>三.format的参数</p><p>%(levelno)s：打印日志级别的数值<br>%(levelname)s：打印日志级别的名称<br>%(pathname)s：打印当前执行程序的路径，其实就是sys.argv[0]<br>%(filename)s：打印当前执行程序名<br>%(funcName)s：打印日志的当前函数<br>%(lineno)d：打印日志的当前行号<br>%(asctime)s：打印日志的时间<br>%(thread)d：打印线程ID<br>%(threadName)s：打印线程名称<br>%(process)d：打印进程ID<br>%(message)s：打印日志信息</p><p>四.保存日志文件</p><p>使用的是logging.FileHandler(路径)</p><pre><code class="python">import logging#创建一个日志记录器logger = logging.getLogger(_name_)#设置日记级别logger.setLevel(logging.INFO)#创建一个FileHandler,并设置日志文件路径log_file = &#39;XXX.log&#39;handler = logging.FileHandler(log_file)#创建一个格式化器formatter = logging.Formatter(&quot;%(asctime)s - %(name)s - %(levelname)s - %(message)s&quot;)#将格式化器添加到处理器handler.setFormatter(formatter)#将处理器添加到日志记录器logger.addHandler(handler)#输出日志消息logger.info(&quot;this is an info message&quot;)logger.warning(&quot;this is a warning message&quot;)</code></pre><p>五.日志记录在迭代训练中的应用</p><pre><code class="python">import logging# 配置日志记录器logging.basicConfig(level=logging.INFO, format=&#39;%(asctime)s - %(levelname)s - %(message)s&#39;)# 模拟迭代训练过程for epoch in range(1, 6):    # 在每个epoch开始时记录信息    logging.info(f&quot;Epoch &#123;epoch&#125; started.&quot;)    # 在每个迭代中记录迭代号和损失值    for iteration in range(1, 11):        loss = 0.1 * iteration  # 这里仅作示例，假设损失值为0.1 * 迭代号        logging.info(f&quot;Iteration &#123;iteration&#125;: Loss = &#123;loss:.4f&#125;&quot;)    # 在每个epoch结束时记录信息    logging.info(f&quot;Epoch &#123;epoch&#125; ended.&quot;)</code></pre>]]></content>
      
      
      <categories>
          
          <category> 可视化记录 </category>
          
      </categories>
      
      
    </entry>
    
    
    
    <entry>
      <title>分词(jieba库)</title>
      <link href="/2024/04/22/fen-ci-jieba-ku/"/>
      <url>/2024/04/22/fen-ci-jieba-ku/</url>
      
        <content type="html"><![CDATA[<p>jieba库是基于统计学的中文分词词库</p><p>1.第一步是先导入jieba库</p><pre><code class="python">import jieba</code></pre><ol start="2"><li>jieba的模式</li></ol><p>1)cut_all&#x3D;True 即全模式</p><pre><code class="python">seg_list=jieba.cut(&quot;我来到北京清华大学&quot;,cut_all=True)print(&quot;Full Mode:&quot;+&#39;/&#39;.join(seg_list))</code></pre><p>seg_list保存的所有的可能分词结果</p><p>‘#’.join(seg_list),其中的#代表每个分词的 分隔符号</p><pre><code class="python"></code></pre>]]></content>
      
      
      <categories>
          
          <category> 自然语言处理 </category>
          
      </categories>
      
      
    </entry>
    
    
    
    <entry>
      <title>正则表达式(re库)</title>
      <link href="/2024/04/22/wen-ben-shu-ju-chu-li/"/>
      <url>/2024/04/22/wen-ben-shu-ju-chu-li/</url>
      
        <content type="html"><![CDATA[<p>正则表达式</p><p>1)首先我们先导入re库，我们可以快速的使用正则匹配</p><pre><code>import re</code></pre><p>2)re中常用的功能有<br>a.</p><pre><code>re.match()</code></pre><p>该指令会从字符串首字符开始匹配，若是首字符匹配不到，则会返回错误。</p><p>b.</p><pre><code>re.search()</code></pre><p>该指令可以从任意位置匹配对应,但只会返回一个匹配成功的字符串，没有匹配到的话则会返回None</p><p>c.</p><pre><code>re.findall()</code></pre><p>9</p>]]></content>
      
      
      <categories>
          
          <category> 数据预处理 </category>
          
      </categories>
      
      
    </entry>
    
    
    
    <entry>
      <title>文本数据读取</title>
      <link href="/2024/04/21/wen-ben-shu-ju-du-qu/"/>
      <url>/2024/04/21/wen-ben-shu-ju-du-qu/</url>
      
        <content type="html"><![CDATA[<p>属于数据预处理的范畴，而文本数据读取是自然语言的第一步</p><p>本章有四个知识点</p><p>1.txt文本数据的读写</p><p>2.CSV以及Excel文本数据的读写</p><p>3.更多的DataFrame的操作</p><p>4.对大规模数据的压缩</p><p>一.txt文本数据的读写</p><p>a. Python内置函数open()和write()可以实现对txt文本的读取或写入操作</p><p>   open(“文件路径”,”读写模式”,encoding&#x3D;”编码格式”)</p><p>文件路径:一般为绝对路径，因为数据就放在程序的文件夹中</p><p>读写模式: 通俗讲就是对文件进行如何的操作,以下是常用的模式</p><ol><li><p>r:读取文件，文件不存在会报错<br>rb:读取二进制文件,文件不存在会报错<br>r+:可读可写，文件不存在会报错，写入操作时会覆盖原文件。</p></li><li><p>w:写入文件,若文件不存在则会先创建再写入，存在则覆盖原文件<br>wb:写入二进制文件，若文件不存在则会先创建再写入，存在则覆盖原文件<br>w+:可读可写，文件不存在则先创建，若存在则会覆盖。</p></li><li><p>a:写入文件，若文件不存在则会先创建再写入，存在不会覆盖原文件，会在源文件后续写。<br>a+:可读可写，文件不存在会先创建，若不存在则不会覆盖，在文件中继续写入内容。</p></li></ol><p>编码格式: 一般用 utf-8 </p><p>注：utf-8（8 位元，Universal Character Set&#x2F;Unicode Transformation Format）是针对 Unicode 的一种可变长度字符编码。它可以用来表示 Unicode 标准中的任何字符，而且其编码中的第一个字节仍与 ASCII 相容，使得原来处理 ASCII 字符的软件无须或只进行少部份修改后，便可继续使用。因此，它逐渐成为电子邮件、网页及其他存储或传送文字的应用中，优先采用的编码。</p><p>b.read(),readlines(),readline()的区别</p><p>1)若</p><p>   f&#x3D;open(“file_path”,”w”,encoding&#x3D;”utf-8”)</p><p>则用<br>   a&#x3D;f.read()  #读取整个文件存放到一个str变量中，若文件过大则无法使用该方法<br>   b&#x3D;f.readline() #每次只读取文件的一行，将每一行读到的数据存放到一个str变量中，可在文件过大时使用<br>   c&#x3D;f.readlines()  #按行读取整个文件内容，并将内容存放到一个list中<br>调用函数。</p><p>2)type(a)是str   type(b)是str type(c)是list</p><p>3)readline()方法</p><p>   f &#x3D; open(“poem.txt”,”r”, encoding&#x3D;”utf-8”)<br>   while True:<br>      poem_line &#x3D; f.readline()<br>      if poem_line:<br>      print(type(poem_line), poem_line)  # 分次返回每一$行<br>   else:<br>      break</p><p>c. write()</p><p>   f.write(“内容”)<br>在open()函数中已经确定了写入内容的模式</p><p>二.CSV及Excel文本数据的读写</p><p>基于pandas对不同类型的文件数据进行操作</p><p>先导入库<br>   import pandas as pd</p><p>传入数据</p><p>   df&#x3D;pd.DataFrame(data)</p><p>一些对数据集的操作</p><p>   df&#x3D;df.T #将数据集进行转置</p><p>   df.to_csv(“数据集名称.csv”,encoding&#x3D;’utf-8’) #将df的内容保存在csv文件内</p><p>用read_csv()读取刚生成的文件</p><p>   df&#x3D;pd.read_csv(“刚保存文件的绝对路径”,index_col&#x3D;0) #index_col&#x3D;0 表示将第一列作为索引</p><p>读写的更多操作:</p><p>保存</p><pre><code class="python">pd.to_excel(&quot;name.xlsx&quot;)pd.to_json()pd.to_sql()pd.to_pickle()</code></pre><p>读取</p><pre><code class="python">pd.read_excel()pd.read_json()pd.read_html()pd.read_sql()pd.read_pickle()</code></pre><p>三.更多DataFrame操作</p><p>1)loc[] 可以获得指定行和列 名称的数据<br>获取在”a”行”b”列的数据<br><code>df.loc[&quot;a&quot;,&quot;b&quot;]</code><br>直接根据列名获取,即获取”b”列的数据<br><code>df.loc[&quot;b&quot;]</code><br>获取多列数据，即获取”b”列和”c”列的数据<br><code>df.loc[[&quot;b&quot;,&quot;c&quot;]]</code></p><p>2)iloc[] 获取某一行<br>操作格式</p><pre><code class="python">df.iloc[[行],[列]]</code></pre><p>第一行所有列</p><pre><code class="python">df.iloc[[1],]</code></pre><p>获得1到3行</p><pre><code class="python">df.iloc[[1,4],]</code></pre><p>获取0到2行，1,2,3列</p><pre><code class="python">df.iloc[[0,2],[1,2,3]]</code></pre><p>3)在loc中使用条件限定<br>根据条件获取数据，如获取亚洲国家对应的数据。</p><pre><code class="python">df.loc[df[&quot;CONT&quot;] == &quot;Asia&quot;]</code></pre><p>若需要满足多个条件，用 &amp; 连接即可。</p><pre><code class="python">df.loc[(df[&quot;CONT&quot;] == &quot;Asia&quot;) &amp; (df[&quot;GDP&quot;] &gt; 1000)]  # 注意 &amp; 左右两边的条件要加上（），否则报错</code></pre><p>4)直接应用 DataFrame 中的 plot() 函数可以对数值类型的列进行画图</p><pre><code class="python">df.plot.bar()</code></pre><p>也可以只选取其中的某部分感兴趣的数据进行画图。</p><pre><code class="python">df[&quot;POP&quot;].plot.bar()</code></pre>]]></content>
      
      
      <categories>
          
          <category> 数据预处理 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 数据预处理 </tag>
            
        </tags>
      
    </entry>
    
    
  
  
</search>
